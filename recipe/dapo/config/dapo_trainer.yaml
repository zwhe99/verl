hydra:
  searchpath:
    - file://verl/trainer/config
    - file://verl/verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  gen_batch_size: ${data.train_batch_size}

reward_model:
  reward_manager: dapo
  reward_kwargs:
    overlong_buffer_cfg: 
      enable: False # We try to avoid forgetting to set enable
      len: 0
      penalty_factor: 0.0
      log: False
    max_resp_len: ${data.max_response_length}

algorithm:
  filter_groups:
    enable: False # We try to avoid forgetting to set enable
    metric: null # acc / score / seq_reward / seq_final_reward / ...
    max_num_gen_batches: 0 # Non-positive values mean no upper limit

trainer:
  project_name: verl-dapo
